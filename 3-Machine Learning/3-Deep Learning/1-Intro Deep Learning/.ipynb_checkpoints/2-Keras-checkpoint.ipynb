{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-14 12:47:31.351301: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:47:31.351318: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta celda se debe ejecutar una sola vez\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-14 12:45:02.962200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-14 12:45:02.962550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:45:02.962579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:45:02.962601: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:45:02.962623: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:45:02.962646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:45:02.962665: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:45:02.962685: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:45:02.962706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:45:02.962711: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-14 12:45:02.963108: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28))) #Input layer\n",
    "model.add(keras.layers.Dense(300, activation = 'relu')) #Hidden layer\n",
    "model.add(keras.layers.Dense(100, activation = 'relu')) #Hidden layer\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax')) #Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-14 12:47:50.949512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-14 12:47:50.949837: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:47:50.949864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:47:50.949885: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:47:50.949906: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:47:50.949929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:47:50.949949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:47:50.949970: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:47:50.949991: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-09-14 12:47:50.949996: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-14 12:47:50.950247: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(300, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "]\n",
    "\n",
    "model = keras.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Flatten at 0x7fdd499108b0>,\n",
       " <keras.layers.core.Dense at 0x7fdd499101c0>,\n",
       " <keras.layers.core.Dense at 0x7fdd52b2d070>,\n",
       " <keras.layers.core.Dense at 0x7fdd52b2d3a0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02989004, -0.0013679 ,  0.02384138, ...,  0.0716759 ,\n",
       "         0.04747208, -0.05276591],\n",
       "       [-0.07393462,  0.05538675,  0.01205418, ..., -0.03834323,\n",
       "         0.02322552, -0.01466092],\n",
       "       [ 0.06902184,  0.04943595, -0.04662535, ..., -0.02901402,\n",
       "        -0.01971202,  0.0305252 ],\n",
       "       ...,\n",
       "       [-0.01008613, -0.01439381,  0.03807601, ...,  0.05119069,\n",
       "         0.06156372, -0.03285758],\n",
       "       [ 0.05895877,  0.04406012,  0.01414423, ...,  0.05022259,\n",
       "         0.00184486, -0.03279894],\n",
       "       [-0.05346923,  0.05145916, -0.00220145, ...,  0.0517759 ,\n",
       "        -0.01476304,  0.0018737 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_1 = model.layers[1]\n",
    "weights, biases = hidden_1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = 'sgd',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-14 12:48:08.471436: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.8918 - accuracy: 0.7816 - val_loss: 0.3934 - val_accuracy: 0.8980\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3741 - accuracy: 0.8964 - val_loss: 0.2999 - val_accuracy: 0.9171\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3092 - accuracy: 0.9124 - val_loss: 0.2661 - val_accuracy: 0.9240\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.2751 - accuracy: 0.9215 - val_loss: 0.2526 - val_accuracy: 0.9276\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.9296 - val_loss: 0.2228 - val_accuracy: 0.9375\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.2295 - accuracy: 0.9347 - val_loss: 0.2100 - val_accuracy: 0.9417\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.2125 - accuracy: 0.9399 - val_loss: 0.1954 - val_accuracy: 0.9474\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1978 - accuracy: 0.9435 - val_loss: 0.1830 - val_accuracy: 0.9510\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1854 - accuracy: 0.9475 - val_loss: 0.1750 - val_accuracy: 0.9522\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1740 - accuracy: 0.9508 - val_loss: 0.1666 - val_accuracy: 0.9530\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1639 - accuracy: 0.9537 - val_loss: 0.1584 - val_accuracy: 0.9562\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1548 - accuracy: 0.9566 - val_loss: 0.1513 - val_accuracy: 0.9575\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1468 - accuracy: 0.9585 - val_loss: 0.1451 - val_accuracy: 0.9602\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1393 - accuracy: 0.9600 - val_loss: 0.1468 - val_accuracy: 0.9604\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1323 - accuracy: 0.9622 - val_loss: 0.1355 - val_accuracy: 0.9628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0aafe065e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=15, batch_size=64, validation_data = (X_val, y_val)) #validation_split = 0.1 (va en %)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1260 - accuracy: 0.9640 - val_loss: 0.1316 - val_accuracy: 0.9644\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.9659 - val_loss: 0.1259 - val_accuracy: 0.9664\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1147 - accuracy: 0.9677 - val_loss: 0.1222 - val_accuracy: 0.9664\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1098 - accuracy: 0.9689 - val_loss: 0.1200 - val_accuracy: 0.9665\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.1052 - accuracy: 0.9707 - val_loss: 0.1166 - val_accuracy: 0.9672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0aa42d88b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 5, 'steps': 782}\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.12598483264446259,\n",
       "  0.12032552808523178,\n",
       "  0.1146988570690155,\n",
       "  0.10982201993465424,\n",
       "  0.1051970049738884],\n",
       " 'accuracy': [0.9640399813652039,\n",
       "  0.9659000039100647,\n",
       "  0.9676799774169922,\n",
       "  0.968940019607544,\n",
       "  0.9706599712371826],\n",
       " 'val_loss': [0.13157114386558533,\n",
       "  0.1258690506219864,\n",
       "  0.12222503870725632,\n",
       "  0.11999332159757614,\n",
       "  0.11655150353908539],\n",
       " 'val_accuracy': [0.9643999934196472,\n",
       "  0.9664000272750854,\n",
       "  0.9664000272750854,\n",
       "  0.9664999842643738,\n",
       "  0.967199981212616]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.history.params)\n",
    "print(model.history.epoch)\n",
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(model.history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 520us/step - loss: 0.1186 - accuracy: 0.9668\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11860053986310959, 0.9667999744415283]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results #(loss, [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.004, 0.028, 0.   , 0.   , 0.   , 0.968, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 637us/step - loss: 1.2019 - accuracy: 0.0032 - mse: 1.2019 - val_loss: 0.6629 - val_accuracy: 0.0026 - val_mse: 0.6629\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 465us/step - loss: 0.5487 - accuracy: 0.0033 - mse: 0.5487 - val_loss: 0.4934 - val_accuracy: 0.0026 - val_mse: 0.4934\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.4646 - accuracy: 0.0033 - mse: 0.4646 - val_loss: 0.4498 - val_accuracy: 0.0026 - val_mse: 0.4498\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 468us/step - loss: 0.4414 - accuracy: 0.0032 - mse: 0.4414 - val_loss: 0.4347 - val_accuracy: 0.0026 - val_mse: 0.4347\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 480us/step - loss: 0.4281 - accuracy: 0.0032 - mse: 0.4281 - val_loss: 0.4194 - val_accuracy: 0.0026 - val_mse: 0.4194\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 487us/step - loss: 0.4210 - accuracy: 0.0032 - mse: 0.4210 - val_loss: 0.4214 - val_accuracy: 0.0026 - val_mse: 0.4214\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 485us/step - loss: 0.4147 - accuracy: 0.0032 - mse: 0.4147 - val_loss: 0.4050 - val_accuracy: 0.0026 - val_mse: 0.4050\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 482us/step - loss: 0.4080 - accuracy: 0.0033 - mse: 0.4080 - val_loss: 0.3994 - val_accuracy: 0.0026 - val_mse: 0.3994\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 499us/step - loss: 0.4039 - accuracy: 0.0033 - mse: 0.4039 - val_loss: 0.3933 - val_accuracy: 0.0026 - val_mse: 0.3933\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3992 - accuracy: 0.0033 - mse: 0.3992 - val_loss: 0.3922 - val_accuracy: 0.0026 - val_mse: 0.3922\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3937 - accuracy: 0.0033 - mse: 0.3937 - val_loss: 0.3833 - val_accuracy: 0.0026 - val_mse: 0.3833\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 525us/step - loss: 0.3911 - accuracy: 0.0033 - mse: 0.3911 - val_loss: 0.3780 - val_accuracy: 0.0026 - val_mse: 0.3780\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 520us/step - loss: 0.3865 - accuracy: 0.0032 - mse: 0.3865 - val_loss: 0.3788 - val_accuracy: 0.0026 - val_mse: 0.3788\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.3841 - accuracy: 0.0033 - mse: 0.3841 - val_loss: 0.3733 - val_accuracy: 0.0026 - val_mse: 0.3733\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.3798 - accuracy: 0.0033 - mse: 0.3798 - val_loss: 0.3685 - val_accuracy: 0.0026 - val_mse: 0.3685\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.3772 - accuracy: 0.0033 - mse: 0.3772 - val_loss: 0.3683 - val_accuracy: 0.0026 - val_mse: 0.3683\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3769 - accuracy: 0.0033 - mse: 0.3769 - val_loss: 0.3678 - val_accuracy: 0.0026 - val_mse: 0.3678\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 520us/step - loss: 0.3730 - accuracy: 0.0033 - mse: 0.3730 - val_loss: 0.3659 - val_accuracy: 0.0026 - val_mse: 0.3659\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 540us/step - loss: 0.3704 - accuracy: 0.0033 - mse: 0.3704 - val_loss: 0.3594 - val_accuracy: 0.0026 - val_mse: 0.3594\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3680 - accuracy: 0.0033 - mse: 0.3680 - val_loss: 0.3566 - val_accuracy: 0.0026 - val_mse: 0.3566\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = 'mean_squared_error',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy', 'mse'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 343us/step - loss: 0.3531 - accuracy: 0.0027 - mse: 0.3531\n",
      "[0.3531276285648346, 0.0027131782844662666, 0.3531276285648346]\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5986602],\n",
       "       [1.2231882],\n",
       "       [1.8271227],\n",
       "       [3.2275028],\n",
       "       [1.4295579]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 382us/step - loss: 0.3659 - accuracy: 0.0033 - mse: 0.3659\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 400us/step - loss: 0.3643 - accuracy: 0.0033 - mse: 0.3643\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 358us/step - loss: 0.3626 - accuracy: 0.0033 - mse: 0.3626\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 364us/step - loss: 0.3608 - accuracy: 0.0033 - mse: 0.3608\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 380us/step - loss: 0.3586 - accuracy: 0.0032 - mse: 0.3586\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 369us/step - loss: 0.3579 - accuracy: 0.0032 - mse: 0.3579\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 386us/step - loss: 0.3547 - accuracy: 0.0033 - mse: 0.3547\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 367us/step - loss: 0.3545 - accuracy: 0.0032 - mse: 0.3545\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 376us/step - loss: 0.3528 - accuracy: 0.0032 - mse: 0.3528\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 399us/step - loss: 0.3540 - accuracy: 0.0033 - mse: 0.3540\n"
     ]
    }
   ],
   "source": [
    "checkpoint_vb = keras.callbacks.ModelCheckpoint('callback_model.h5')\n",
    "history = model.fit(X_train, y_train, epochs = 10, callbacks = [checkpoint_vb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 513us/step - loss: 0.3360 - accuracy: 0.0033 - mse: 0.3360 - val_loss: 0.3316 - val_accuracy: 0.0026 - val_mse: 0.3316\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 491us/step - loss: 0.3348 - accuracy: 0.0033 - mse: 0.3348 - val_loss: 0.3251 - val_accuracy: 0.0026 - val_mse: 0.3251\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 509us/step - loss: 0.3368 - accuracy: 0.0033 - mse: 0.3368 - val_loss: 0.3254 - val_accuracy: 0.0026 - val_mse: 0.3254\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 478us/step - loss: 0.3390 - accuracy: 0.0033 - mse: 0.3390 - val_loss: 0.3294 - val_accuracy: 0.0026 - val_mse: 0.3294\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 482us/step - loss: 0.3332 - accuracy: 0.0033 - mse: 0.3332 - val_loss: 0.3298 - val_accuracy: 0.0026 - val_mse: 0.3298\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 479us/step - loss: 0.3326 - accuracy: 0.0033 - mse: 0.3326 - val_loss: 0.3248 - val_accuracy: 0.0026 - val_mse: 0.3248\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 483us/step - loss: 0.3338 - accuracy: 0.0033 - mse: 0.3338 - val_loss: 0.3247 - val_accuracy: 0.0026 - val_mse: 0.3247\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3292 - accuracy: 0.0033 - mse: 0.3292 - val_loss: 0.3272 - val_accuracy: 0.0026 - val_mse: 0.3272\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 482us/step - loss: 0.3302 - accuracy: 0.0033 - mse: 0.3302 - val_loss: 0.3236 - val_accuracy: 0.0026 - val_mse: 0.3236\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 485us/step - loss: 0.3293 - accuracy: 0.0032 - mse: 0.3293 - val_loss: 0.3203 - val_accuracy: 0.0026 - val_mse: 0.3203\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 493us/step - loss: 0.3280 - accuracy: 0.0032 - mse: 0.3280 - val_loss: 0.3253 - val_accuracy: 0.0026 - val_mse: 0.3253\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 491us/step - loss: 0.3278 - accuracy: 0.0033 - mse: 0.3278 - val_loss: 0.3243 - val_accuracy: 0.0026 - val_mse: 0.3243\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.3268 - accuracy: 0.0033 - mse: 0.3268 - val_loss: 0.3217 - val_accuracy: 0.0026 - val_mse: 0.3217\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 498us/step - loss: 0.3276 - accuracy: 0.0033 - mse: 0.3276 - val_loss: 0.3189 - val_accuracy: 0.0026 - val_mse: 0.3189\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 485us/step - loss: 0.3374 - accuracy: 0.0033 - mse: 0.3374 - val_loss: 0.3194 - val_accuracy: 0.0026 - val_mse: 0.3194\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 494us/step - loss: 0.3283 - accuracy: 0.0032 - mse: 0.3283 - val_loss: 0.3208 - val_accuracy: 0.0026 - val_mse: 0.3208\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 529us/step - loss: 0.3288 - accuracy: 0.0032 - mse: 0.3288 - val_loss: 0.3213 - val_accuracy: 0.0026 - val_mse: 0.3213\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.3273 - accuracy: 0.0033 - mse: 0.3273 - val_loss: 0.3168 - val_accuracy: 0.0026 - val_mse: 0.3168\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3296 - accuracy: 0.0033 - mse: 0.3296 - val_loss: 0.3152 - val_accuracy: 0.0026 - val_mse: 0.3152\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3267 - accuracy: 0.0033 - mse: 0.3267 - val_loss: 0.3215 - val_accuracy: 0.0026 - val_mse: 0.3215\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 505us/step - loss: 0.3347 - accuracy: 0.0033 - mse: 0.3347 - val_loss: 0.3159 - val_accuracy: 0.0026 - val_mse: 0.3159\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3292 - accuracy: 0.0033 - mse: 0.3292 - val_loss: 0.3251 - val_accuracy: 0.0026 - val_mse: 0.3251\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 552us/step - loss: 0.3299 - accuracy: 0.0033 - mse: 0.3299 - val_loss: 0.3169 - val_accuracy: 0.0026 - val_mse: 0.3169\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3229 - accuracy: 0.0033 - mse: 0.3229 - val_loss: 0.3150 - val_accuracy: 0.0026 - val_mse: 0.3150\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 497us/step - loss: 0.3219 - accuracy: 0.0033 - mse: 0.3219 - val_loss: 0.3137 - val_accuracy: 0.0026 - val_mse: 0.3137\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.3227 - accuracy: 0.0033 - mse: 0.3227 - val_loss: 0.3157 - val_accuracy: 0.0026 - val_mse: 0.3157\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3305 - accuracy: 0.0033 - mse: 0.3305 - val_loss: 0.3168 - val_accuracy: 0.0026 - val_mse: 0.3168\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.3216 - accuracy: 0.0033 - mse: 0.3216 - val_loss: 0.3188 - val_accuracy: 0.0026 - val_mse: 0.3188\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3226 - accuracy: 0.0033 - mse: 0.3226 - val_loss: 0.3111 - val_accuracy: 0.0026 - val_mse: 0.3111\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 518us/step - loss: 0.3208 - accuracy: 0.0033 - mse: 0.3208 - val_loss: 0.3130 - val_accuracy: 0.0026 - val_mse: 0.3130\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3222 - accuracy: 0.0032 - mse: 0.3222 - val_loss: 0.3097 - val_accuracy: 0.0026 - val_mse: 0.3097\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 520us/step - loss: 0.3193 - accuracy: 0.0032 - mse: 0.3193 - val_loss: 0.3128 - val_accuracy: 0.0026 - val_mse: 0.3128\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.3191 - accuracy: 0.0032 - mse: 0.3191 - val_loss: 0.3137 - val_accuracy: 0.0026 - val_mse: 0.3137\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.3176 - accuracy: 0.0032 - mse: 0.3176 - val_loss: 0.3108 - val_accuracy: 0.0026 - val_mse: 0.3108\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 512us/step - loss: 0.3175 - accuracy: 0.0032 - mse: 0.3175 - val_loss: 0.3083 - val_accuracy: 0.0026 - val_mse: 0.3083\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 515us/step - loss: 0.3176 - accuracy: 0.0032 - mse: 0.3176 - val_loss: 0.3112 - val_accuracy: 0.0026 - val_mse: 0.3112\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 515us/step - loss: 0.3242 - accuracy: 0.0032 - mse: 0.3242 - val_loss: 0.3392 - val_accuracy: 0.0026 - val_mse: 0.3392\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 549us/step - loss: 0.3184 - accuracy: 0.0033 - mse: 0.3184 - val_loss: 0.3104 - val_accuracy: 0.0026 - val_mse: 0.3104\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 516us/step - loss: 0.3181 - accuracy: 0.0033 - mse: 0.3181 - val_loss: 0.3171 - val_accuracy: 0.0026 - val_mse: 0.3171\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 490us/step - loss: 0.3186 - accuracy: 0.0033 - mse: 0.3186 - val_loss: 0.3108 - val_accuracy: 0.0026 - val_mse: 0.3108\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "history = model.fit(X_train, y_train, epochs = 100, validation_data = (X_valid, y_valid), callbacks = [checkpoint_vb, early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
