{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador paisajes\n",
    "Para este ejercicio vas a crear un clasificador automático de paisajes. Los datos los encontrarás en el Clasroom como `seg_train.zip` y `seg_test.zip`. Se pide:\n",
    "1. Cargar las imágenes. Mira cómo están almacenados los datos. Tendrás que recorrer las carpetas, cargar las imágenes en memoria y etiquetarlas con los nombres de las carpetas. Realiza un reshape de cada imagen (comienza el ejercicio con 32x32, para ir más rápido en las ejecuciones).\n",
    "2. Investiga las imágenes, comprueba con algunas muestras que has cargado bien los datos.\n",
    "3. Normaliza\n",
    "4. Diseña la arquitectura de la red. Recuerda que es un algiritmo de clasificación. Ojo con las dimensiones de la entrada\n",
    "5. Reserva un 20% de los datos del entrenamiento para validar.\n",
    "6. Representa el objeto history\n",
    "7. Evalua el modelo con los datos de test\n",
    "8. Representa algunos de los paisajes donde el modelo comete errores\n",
    "9. Crea una matriz de confusión con los errores del modelo\n",
    "\n",
    "**NOTA apartado 1**: para el apartado 1 tendras que recorre las carpetas/imagenes con `os.listdir()`, e ir cargando todas las imagenes como arrays de numpy\n",
    "\n",
    "**NOTA apartado 4**: empieza con un par de capas Conv2D + MaxPooling2D con activación relu y después la fully connected layer. on softmax como ultima capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/home/gonzalo/Documentos/Data_Science/dataset_practica_redes_convol/'\n",
    "\n",
    "SEG_TRAIN_FOLDER = ROOT_PATH + 'seg_train/'\n",
    "SEG_TEST_FOLDER = ROOT_PATH + 'seg_test/'\n",
    "\n",
    "TRAIN_PATH = SEG_TRAIN_FOLDER\n",
    "TEST_PATH = SEG_TEST_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificamos los datos y creamos el dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cateory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15346.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1317.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8228.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1693.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12789.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename    cateory\n",
       "0  15346.jpg  buildings\n",
       "1   1317.jpg  buildings\n",
       "2   8228.jpg  buildings\n",
       "3   1693.jpg  buildings\n",
       "4  12789.jpg  buildings"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "\n",
    "filenames = []\n",
    "folders = []\n",
    "    \n",
    "image_folders = os.listdir(TRAIN_PATH)\n",
    "for folder in image_folders:\n",
    "    file = TRAIN_PATH + folder + '/'\n",
    "    filename = os.listdir(file)\n",
    "    \n",
    "    for name in filename:\n",
    "        filenames.append(name)\n",
    "        folders.append(folder)\n",
    "    \n",
    "df_train = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'cateory': folders\n",
    "})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cateory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20441.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21445.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21233.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21689.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22058.jpg</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename    cateory\n",
       "0  20441.jpg  buildings\n",
       "1  21445.jpg  buildings\n",
       "2  21233.jpg  buildings\n",
       "3  21689.jpg  buildings\n",
       "4  22058.jpg  buildings"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "\n",
    "filenames = []\n",
    "folders = []\n",
    "    \n",
    "image_folders = os.listdir(TEST_PATH)\n",
    "for folder in image_folders:\n",
    "    file = TEST_PATH + folder + '/'\n",
    "    filename = os.listdir(file)\n",
    "    \n",
    "    for name in filename:\n",
    "        filenames.append(name)\n",
    "        folders.append(folder)\n",
    "    \n",
    "df_test = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'cateory': folders\n",
    "})\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescalamos las imagenes a un tamaño de 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14034, 32, 32, 3)\n",
      "(3000, 32, 32, 3)\n",
      "(14034,)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rescal_images(path, height, width):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    image_folders = os.listdir(path)\n",
    "    for folder in image_folders:\n",
    "        file = path + folder + '/'\n",
    "        filename = os.listdir(file)\n",
    "    \n",
    "        for name in filename:\n",
    "            image = imread(path + folder + '/' + name)\n",
    "            image_small = cv2.resize(image, (height, width))\n",
    "            \n",
    "            X.append(image_small)\n",
    "            y.append(folder)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = rescal_images(TRAIN_PATH, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "X_test, y_test = rescal_images(TEST_PATH, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_test[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0\n",
      "Max: 255\n"
     ]
    }
   ],
   "source": [
    "print('Min:', np.min(X_train))\n",
    "print('Max:', np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0\n",
      "Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(\"Min:\", np.min(X_train))\n",
    "print(\"Max:\", np.max(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montamos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "layers = [\n",
    "    keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (IMAGE_SIZE[0], IMAGE_SIZE[1], IMAGE_SIZE[2])),\n",
    "    keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(6, activation = 'softmax')\n",
    "]\n",
    "\n",
    "model = keras.Sequential(layers)\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 666,374\n",
      "Trainable params: 666,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-16 13:52:02.755522: W tensorflow/core/framework/op_kernel.cc:1669] OP_REQUIRES failed at cast_op.cc:121 : Unimplemented: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node sparse_categorical_crossentropy/Cast (defined at tmp/ipykernel_35021/1104540093.py:1) ]] [Op:__inference_train_function_3888]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35021/1104540093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(X_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Documentos/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node sparse_categorical_crossentropy/Cast (defined at tmp/ipykernel_35021/1104540093.py:1) ]] [Op:__inference_train_function_3888]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs = 50,\n",
    "          batch_size = 64,\n",
    "          validation_split = 0.2,\n",
    "          callbacks = [earlystop],\n",
    "          verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
